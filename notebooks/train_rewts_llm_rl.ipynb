{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ReWTSE-LLM-RL Trading System Training\n",
    "\n",
    "Training notebook for the hybrid LLM+RL trading system.\n",
    "\n",
    "**System Architecture:**\n",
    "- LLM Agent (Google Gemini): Generates strategic trading signals\n",
    "- RL Agent (DDQN): Learns tactical execution policies\n",
    "- ReWTSE Ensemble: Weighted ensemble with QP optimization\n",
    "\n",
    "**Usage:**\n",
    "- **Local**: Navigate to project directory and run `jupyter notebook` or use VS Code\n",
    "- **Google Colab**: Upload to Colab, mount Drive, and run all cells\n",
    "\n",
    "The notebook automatically detects if running on Colab or locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "\n",
      "PyTorch version: 2.9.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Detect environment (Colab or Local)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"Running locally\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Google Drive mount (not on Colab)\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive (only on Colab)\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted!\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "setup_project"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Setup:\n",
      "Make sure you're in the project root directory\n",
      "\n",
      "Current working directory: /Users/m.zingaretti/UNI/Papers\n",
      "\n",
      "Directory contents:\n",
      "total 5248\n",
      "drwxr-xr-x  25 m.zingaretti  staff      800 Oct 19 16:33 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  16 m.zingaretti  staff      512 Oct 19 16:11 \u001b[34m..\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 m.zingaretti  staff    10244 Oct 19 14:50 .DS_Store\n",
      "drwx------@  3 m.zingaretti  staff       96 Oct 19 17:21 \u001b[34m.claude\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 m.zingaretti  staff      383 Oct 19 17:14 .env.example\n",
      "drwxr-xr-x@  9 m.zingaretti  staff      288 Oct 19 17:03 \u001b[34m.git\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 m.zingaretti  staff      610 Oct 19 17:14 .gitignore\n",
      "-rw-r--r--@  1 m.zingaretti  staff    23424 Oct 11 18:51 AI_Evaluation_Metrics.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff    12307 Oct 11 18:48 Alpaca_Paper_Trading_Guide.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff    14962 Oct 11 18:32 Financial_Metrics_Guide.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff    14037 Oct 11 18:45 Hardware_Requirements.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff  1299490 Sep  5 10:50 Language Model Guided RL Quantative Trading.pdf\n",
      "-rw-r--r--@  1 m.zingaretti  staff    11030 Oct 11 18:52 README.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff    63395 Oct 11 12:45 ReWTSE-LLM-RL_Implementation_Guide.md\n",
      "-rw-r--r--@  1 m.zingaretti  staff  1205524 Sep  9 10:58 ReWTSE.pdf\n",
      "drwxr-xr-x@  3 m.zingaretti  staff       96 Oct 11 18:25 \u001b[34mconfigs\u001b[m\u001b[m\n",
      "drwxr-xr-x@  6 m.zingaretti  staff      192 Oct 19 14:50 \u001b[34mdata\u001b[m\u001b[m\n",
      "drwx------@  2 m.zingaretti  staff       64 Oct 19 17:04 \u001b[34mdocs\u001b[m\u001b[m\n",
      "drwxr-xr-x@  3 m.zingaretti  staff       96 Oct 11 18:34 \u001b[34mmodels\u001b[m\u001b[m\n",
      "drwxr-xr-x@  7 m.zingaretti  staff      224 Oct 19 17:23 \u001b[34mnotebooks\u001b[m\u001b[m\n",
      "-rw-r--r--@  1 m.zingaretti  staff      698 Oct 11 18:33 requirements.txt\n",
      "drwxr-xr-x@  4 m.zingaretti  staff      128 Oct 11 18:25 \u001b[34mresults\u001b[m\u001b[m\n",
      "drwxr-xr-x@  7 m.zingaretti  staff      224 Oct 19 17:22 \u001b[34mscripts\u001b[m\u001b[m\n",
      "drwxr-xr-x@  7 m.zingaretti  staff      224 Oct 19 17:21 \u001b[34msrc\u001b[m\u001b[m\n",
      "drwxr-xr-x@  8 m.zingaretti  staff      256 Oct 19 14:48 \u001b[34mvenv_rewts_llm\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Setup project path based on environment\n",
    "if IN_COLAB:\n",
    "    print(\"Google Colab Setup:\")\n",
    "    print(\"Choose one option:\\n\")\n",
    "    \n",
    "    # Option 1: Clone from GitHub\n",
    "    print(\"Option 1: Clone from GitHub\")\n",
    "    print(\"  Uncomment the following lines and replace with your repo URL:\")\n",
    "    print(\"  # !git clone https://github.com/YOUR_USERNAME/YOUR_REPO.git\")\n",
    "    print(\"  # %cd YOUR_REPO\\n\")\n",
    "    \n",
    "    # Option 2: Use files from Google Drive\n",
    "    print(\"Option 2: Use files from Google Drive\")\n",
    "    print(\"  Uncomment and modify the path to your project folder:\")\n",
    "    # project_path = '/content/drive/MyDrive/Papers'\n",
    "    # os.chdir(project_path)\n",
    "    \n",
    "    # Option 3: Upload manually\n",
    "    print(\"\\nOption 3: Upload project files manually\")\n",
    "    print(\"  Use the folder icon on the left sidebar to upload files\\n\")\n",
    "else:\n",
    "    print(\"Local Setup:\")\n",
    "    print(\"Make sure you're in the project root directory\\n\")\n",
    "    # Navigate to project root (assuming notebook is in notebooks/)\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('..')\n",
    "        print(\"Changed to project root directory\")\n",
    "\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "print(f\"\\nDirectory contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking and installing dependencies...\n",
      "\n",
      "Local environment detected.\n",
      "Using existing virtual environment or system packages.\n",
      "\n",
      "If you get import errors, install dependencies with:\n",
      "  pip install -r requirements.txt\n",
      "\n",
      "Or install individually:\n",
      "  pip install google-generativeai torch gym stable-baselines3\n",
      "  pip install pandas numpy matplotlib seaborn yfinance cvxopt tqdm pyyaml\n",
      "\n",
      "✓ Dependencies check complete!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "print(\"Checking and installing dependencies...\\n\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Installing all dependencies on Colab...\")\n",
    "    !pip install -q google-generativeai>=0.3.0\n",
    "    !pip install -q torch>=2.0.0 torchvision>=0.15.0\n",
    "    !pip install -q gym>=0.26.0\n",
    "    !pip install -q stable-baselines3>=2.0.0\n",
    "    !pip install -q pandas>=1.5.0 numpy>=1.23.0\n",
    "    !pip install -q matplotlib>=3.6.0 seaborn>=0.12.0\n",
    "    !pip install -q yfinance>=0.2.0\n",
    "    !pip install -q cvxopt>=1.3.0\n",
    "    !pip install -q tqdm>=4.64.0\n",
    "    !pip install -q pyyaml>=6.0\n",
    "else:\n",
    "    print(\"Local environment detected.\")\n",
    "    print(\"Using existing virtual environment or system packages.\")\n",
    "    print(\"\\nIf you get import errors, install dependencies with:\")\n",
    "    print(\"  pip install -r requirements.txt\")\n",
    "    print(\"\\nOr install individually:\")\n",
    "    print(\"  pip install google-generativeai torch gym stable-baselines3\")\n",
    "    print(\"  pip install pandas numpy matplotlib seaborn yfinance cvxopt tqdm pyyaml\")\n",
    "\n",
    "print(\"\\n✓ Dependencies check complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "api_setup"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GEMINI_API_KEY from environment variables\n",
      "\n",
      "✓ API key configured!\n"
     ]
    }
   ],
   "source": [
    "# API Configuration\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your Gemini API key\n",
    "# Get your API key from: https://makersuite.google.com/app/apikey\n",
    "\n",
    "# Check if already set in environment\n",
    "if os.getenv('GEMINI_API_KEY'):\n",
    "    print(\"Using GEMINI_API_KEY from environment variables\")\n",
    "    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "else:\n",
    "    print(\"Enter your Gemini API Key (input will be hidden)\")\n",
    "    GEMINI_API_KEY = getpass('Gemini API Key: ')\n",
    "    os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
    "\n",
    "print(\"\\n✓ API key configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "training_config"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "{\n",
      "  \"tickers\": [\n",
      "    \"AAPL\"\n",
      "  ],\n",
      "  \"rewts\": {\n",
      "    \"chunk_length\": 500,\n",
      "    \"lookback_length\": 100,\n",
      "    \"forecast_horizon\": 1,\n",
      "    \"episodes_per_chunk\": 50,\n",
      "    \"gamma\": 0.99,\n",
      "    \"epsilon_start\": 1.0,\n",
      "    \"epsilon_min\": 0.01,\n",
      "    \"epsilon_decay\": 0.995,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"batch_size\": 64,\n",
      "    \"buffer_size\": 10000,\n",
      "    \"target_update_freq\": 10,\n",
      "    \"hidden_dims\": [\n",
      "      128,\n",
      "      64\n",
      "    ]\n",
      "  },\n",
      "  \"trading_env\": {\n",
      "    \"initial_balance\": 10000,\n",
      "    \"transaction_cost\": 0.001,\n",
      "    \"max_position\": 1.0\n",
      "  },\n",
      "  \"strategy_frequency\": 20\n",
      "}\n",
      "\n",
      "LLM Model: gemini-2.0-flash-exp\n",
      "Tickers: ['AAPL']\n"
     ]
    }
   ],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    'tickers': ['AAPL'],  # Add more tickers as needed\n",
    "    \n",
    "    # LLM Configuration (Google Gemini)\n",
    "    'llm': {\n",
    "        'llm_model': 'gemini-2.0-flash-exp',  # Or 'gemini-pro' for better quality\n",
    "        'temperature': 0.0,  # Deterministic for reproducibility\n",
    "        'seed': 49,\n",
    "        'gemini_api_key': os.getenv('GEMINI_API_KEY')\n",
    "    },\n",
    "    \n",
    "    # ReWTSE Ensemble Configuration\n",
    "    'rewts': {\n",
    "        'chunk_length': 500,  # Number of trading days per chunk\n",
    "        'lookback_length': 100,  # Lookback period for weight optimization\n",
    "        'forecast_horizon': 1,  # Steps ahead to forecast\n",
    "        'episodes_per_chunk': 50,  # Training episodes per chunk (increase for better results)\n",
    "        'gamma': 0.99,  # Discount factor\n",
    "        'epsilon_start': 1.0,  # Initial exploration rate\n",
    "        'epsilon_min': 0.01,  # Minimum exploration rate\n",
    "        'epsilon_decay': 0.995,  # Exploration decay rate\n",
    "        'learning_rate': 1e-3,  # Adam learning rate\n",
    "        'batch_size': 64,  # Mini-batch size\n",
    "        'buffer_size': 10000,  # Replay buffer size\n",
    "        'target_update_freq': 10,  # Target network update frequency\n",
    "        'hidden_dims': [128, 64]  # Neural network architecture\n",
    "    },\n",
    "    \n",
    "    # Trading Environment Configuration\n",
    "    'trading_env': {\n",
    "        'initial_balance': 10000,  # Starting capital\n",
    "        'transaction_cost': 0.001,  # 0.1% transaction cost\n",
    "        'max_position': 1.0  # Maximum position size (1.0 = 100% of capital)\n",
    "    },\n",
    "    \n",
    "    # Strategy generation frequency (days)\n",
    "    'strategy_frequency': 20  # Generate new strategy every 20 trading days (~monthly)\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "import json\n",
    "print(json.dumps({k: v for k, v in config.items() if k != 'llm'}, indent=2))\n",
    "print(f\"\\nLLM Model: {config['llm']['llm_model']}\")\n",
    "print(f\"Tickers: {config['tickers']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_prep"
   },
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "check_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking data for AAPL:\n",
      "  Market data: ✓ (2215 rows, 2012-03-14 00:00:00-04:00 to 2020-12-30 00:00:00-05:00)\n",
      "  News data: ✓ (114 rows)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4b/0sng9dls53x13h5ffn2pfkgr0000gp/T/ipykernel_78610/3847161882.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  news_df = pd.read_csv(news_data_path, index_col=0, parse_dates=True)\n"
     ]
    }
   ],
   "source": [
    "# Check if data files exist\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "for ticker in config['tickers']:\n",
    "    market_data_path = f\"data/processed/{ticker}_full_data.csv\"\n",
    "    news_data_path = f\"data/processed/{ticker}_news.csv\"\n",
    "    \n",
    "    print(f\"\\nChecking data for {ticker}:\")\n",
    "    \n",
    "    if os.path.exists(market_data_path):\n",
    "        df = pd.read_csv(market_data_path, index_col=0, parse_dates=True)\n",
    "        print(f\"  Market data: ✓ ({len(df)} rows, {df.index.min()} to {df.index.max()})\")\n",
    "    else:\n",
    "        print(f\"  Market data: ✗ NOT FOUND at {market_data_path}\")\n",
    "    \n",
    "    if os.path.exists(news_data_path):\n",
    "        news_df = pd.read_csv(news_data_path, index_col=0, parse_dates=True)\n",
    "        print(f\"  News data: ✓ ({len(news_df)} rows)\")\n",
    "    else:\n",
    "        print(f\"  News data: ✗ NOT FOUND at {news_data_path}\")\n",
    "\n",
    "# If data is missing, you need to run the data preprocessing scripts first!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports"
   },
   "source": [
    "## 4. Import Project Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "import_modules"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from src.llm_agents.strategist_agent import StrategistAgent\n",
    "from src.llm_agents.analyst_agent import AnalystAgent\n",
    "from src.rl_agents.trading_env import TradingEnv\n",
    "from src.hybrid_model.ensemble_controller import ReWTSEnsembleController\n",
    "from src.utils.data_utils import load_market_data, load_news_data, filter_news_by_period\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "print(\"Modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 5. Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "### 5.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "load_data"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for AAPL...\n",
      "\n",
      "Market data shape: (2215, 29)\n",
      "News data shape: (114, 4)\n",
      "\n",
      "Market data index type: <class 'pandas.core.indexes.base.Index'>\n",
      "News data index type: <class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n",
      "\n",
      "Market data columns: ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'HV_Close', 'SPX_Close', 'VIX_Close', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist', 'ATR', 'SMA_20_Slope', 'SMA_50_Slope', 'SMA_100_Slope', 'SMA_200_Slope', 'PE_Ratio', 'Debt_to_Equity', 'Current_Ratio', 'ROE', 'Gross_Margin', 'Operating_Margin']\n",
      "News data columns: ['Unnamed: 0', 'headline', 'summary', 'source']\n",
      "\n",
      "Market date range: 2012-03-14 00:00:00-04:00 to 2020-12-30 00:00:00-05:00\n",
      "News date range: 2012-01-03 05:00:00 to 2020-12-24 05:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load data for the first ticker\n",
    "ticker = config['tickers'][0]\n",
    "print(f\"Loading data for {ticker}...\")\n",
    "\n",
    "# Use utility functions for robust data loading\n",
    "market_df = load_market_data(ticker)\n",
    "news_df = load_news_data(ticker)\n",
    "\n",
    "print(f\"\\nMarket data shape: {market_df.shape}\")\n",
    "print(f\"News data shape: {news_df.shape}\")\n",
    "print(f\"\\nMarket data index type: {type(market_df.index)}\")\n",
    "print(f\"News data index type: {type(news_df.index)}\")\n",
    "print(f\"\\nMarket data columns: {list(market_df.columns)}\")\n",
    "print(f\"News data columns: {list(news_df.columns)}\")\n",
    "print(f\"\\nMarket date range: {market_df.index.min()} to {market_df.index.max()}\")\n",
    "print(f\"News date range: {news_df.index.min()} to {news_df.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "### 5.2 Pre-compute LLM Strategies\n",
    "\n",
    "This step generates strategic signals using the Gemini LLM. It may take some time depending on the data size and API rate limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "precompute_strategies"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Pre-computing LLM Strategies for AAPL\n",
      "============================================================\n",
      "Total data points: 2215\n",
      "Strategy frequency: every 20 days\n",
      "Number of strategies to generate: 110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating LLM strategies:   0%|          | 0/110 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760887439.837553 5922972 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n",
      "Generating LLM strategies:   0%|          | 0/110 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gdp_qoq'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 117\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m strategies\n\u001b[32m    116\u001b[39m \u001b[38;5;66;03m# Generate strategies\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m strategies = \u001b[43mprecompute_llm_strategies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnews_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Display sample strategies\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSample strategies:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mprecompute_llm_strategies\u001b[39m\u001b[34m(ticker, market_df, news_df, config)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Generate strategy\u001b[39;00m\n\u001b[32m     92\u001b[39m     last_strategy = strategies[-\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m strategies \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     strategy = \u001b[43mstrategist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_strategy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmarket_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmarket_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfundamentals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfundamentals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43manalytics\u001b[49m\u001b[43m=\u001b[49m\u001b[43manalytics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmacro_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmacro_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnews_signals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnews_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlast_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlast_strategy\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     strategies.append(strategy)\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✓ Generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(strategies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m strategies\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/UNI/Papers/src/llm_agents/strategist_agent.py:214\u001b[39m, in \u001b[36mStrategistAgent.generate_strategy\u001b[39m\u001b[34m(self, market_data, fundamentals, analytics, macro_data, news_signals, last_strategy)\u001b[39m\n\u001b[32m    208\u001b[39m prompt_data = \u001b[38;5;28mself\u001b[39m._prepare_prompt_data(\n\u001b[32m    209\u001b[39m     market_data, fundamentals, analytics,\n\u001b[32m    210\u001b[39m     macro_data, news_signals, last_strategy\n\u001b[32m    211\u001b[39m )\n\u001b[32m    213\u001b[39m \u001b[38;5;66;03m# Formatta il prompt\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m prompt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mprompt_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# Chiamata a Gemini\u001b[39;00m\n\u001b[32m    218\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.model.generate_content(prompt)\n",
      "\u001b[31mKeyError\u001b[39m: 'gdp_qoq'"
     ]
    }
   ],
   "source": [
    "def precompute_llm_strategies(ticker, market_df, news_df, config):\n",
    "    \"\"\"Pre-compute LLM strategies for the entire period\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Pre-computing LLM Strategies for {ticker}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    strategist = StrategistAgent(config['llm'])\n",
    "    analyst = AnalystAgent(config['llm'])\n",
    "    \n",
    "    strategies = []\n",
    "    \n",
    "    # Generate strategies at specified frequency\n",
    "    strategy_frequency = config.get('strategy_frequency', 20)\n",
    "    num_strategies = len(market_df) // strategy_frequency\n",
    "    \n",
    "    print(f\"Total data points: {len(market_df)}\")\n",
    "    print(f\"Strategy frequency: every {strategy_frequency} days\")\n",
    "    print(f\"Number of strategies to generate: {num_strategies}\")\n",
    "    \n",
    "    for i in tqdm(range(num_strategies), desc=\"Generating LLM strategies\"):\n",
    "        start_idx = i * strategy_frequency\n",
    "        end_idx = min((i + 1) * strategy_frequency, len(market_df))\n",
    "        \n",
    "        # Data for this strategy period\n",
    "        period_data = market_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Filter news for this period using utility function\n",
    "        period_news = filter_news_by_period(\n",
    "            news_df,\n",
    "            period_data.index[0],\n",
    "            period_data.index[-1]\n",
    "        )\n",
    "        \n",
    "        # Process news with Analyst Agent\n",
    "        if len(period_news) > 0:\n",
    "            news_signals = analyst.process_news(period_news.to_dict('records'))\n",
    "        else:\n",
    "            # No news available for this period\n",
    "            news_signals = {\n",
    "                'sentiment': 'neutral',\n",
    "                'confidence': 0.5,\n",
    "                'key_topics': []\n",
    "            }\n",
    "        \n",
    "        # Prepare input for Strategist\n",
    "        market_data = {\n",
    "            'timestamp': str(period_data.index[-1]),\n",
    "            'Close': float(period_data['Close'].iloc[-1]),\n",
    "            'Volume': float(period_data['Volume'].iloc[-1]),\n",
    "            'Weekly_Returns': period_data['Close'].pct_change().tail(20).tolist(),\n",
    "            'HV_Close': float(period_data.get('HV_Close', pd.Series([0])).iloc[-1]),\n",
    "            'IV_Close': float(period_data.get('IV_Close', pd.Series([0])).iloc[-1]),\n",
    "            'Beta': 1.0,\n",
    "            'Classification': 'Growth'\n",
    "        }\n",
    "        \n",
    "        fundamentals = {\n",
    "            'current_ratio': float(period_data.get('Current_Ratio', pd.Series([1.5])).iloc[-1]),\n",
    "            'debt_to_equity': float(period_data.get('Debt_to_Equity', pd.Series([0.5])).iloc[-1]),\n",
    "            'pe_ratio': float(period_data.get('PE_Ratio', pd.Series([20])).iloc[-1]),\n",
    "            'gross_margin': float(period_data.get('Gross_Margin', pd.Series([0.4])).iloc[-1]),\n",
    "            'operating_margin': float(period_data.get('Operating_Margin', pd.Series([0.2])).iloc[-1]),\n",
    "            'eps_yoy': 0.1,\n",
    "            'net_income_yoy': 0.1\n",
    "        }\n",
    "        \n",
    "        analytics = {\n",
    "            'ma_20': float(period_data['SMA_20'].iloc[-1]),\n",
    "            'ma_50': float(period_data['SMA_50'].iloc[-1]),\n",
    "            'ma_200': float(period_data['SMA_200'].iloc[-1]),\n",
    "            'ma_20_slope': float(period_data['SMA_20_Slope'].iloc[-1]),\n",
    "            'ma_50_slope': float(period_data['SMA_50_Slope'].iloc[-1]),\n",
    "            'rsi': float(period_data['RSI'].iloc[-1]),\n",
    "            'macd': float(period_data['MACD'].iloc[-1]),\n",
    "            'macd_signal': float(period_data['MACD_Signal'].iloc[-1]),\n",
    "            'atr': float(period_data['ATR'].iloc[-1])\n",
    "        }\n",
    "        \n",
    "        macro_data = {\n",
    "            'SPX_Close': float(period_data.get('SPX_Close', pd.Series([0])).iloc[-1]),\n",
    "            'SPX_Slope': float(period_data['SPX_Close'].diff().iloc[-1]) if 'SPX_Close' in period_data else 0.0,\n",
    "            'VIX_Close': float(period_data.get('VIX_Close', pd.Series([0])).iloc[-1]),\n",
    "            'VIX_Slope': float(period_data['VIX_Close'].diff().iloc[-1]) if 'VIX_Close' in period_data else 0.0,\n",
    "            'GDP_QoQ': 0.0,\n",
    "            'PMI': 50.0,\n",
    "            'PPI_YoY': 0.0,\n",
    "            'Treasury_YoY': 0.0\n",
    "        }\n",
    "        \n",
    "        # Generate strategy\n",
    "        last_strategy = strategies[-1] if strategies else None\n",
    "        \n",
    "        strategy = strategist.generate_strategy(\n",
    "            market_data=market_data,\n",
    "            fundamentals=fundamentals,\n",
    "            analytics=analytics,\n",
    "            macro_data=macro_data,\n",
    "            news_signals=news_signals,\n",
    "            last_strategy=last_strategy\n",
    "        )\n",
    "        \n",
    "        strategies.append(strategy)\n",
    "    \n",
    "    print(f\"\\n✓ Generated {len(strategies)} strategies\")\n",
    "    \n",
    "    # Save strategies\n",
    "    os.makedirs('data/llm_strategies', exist_ok=True)\n",
    "    with open(f\"data/llm_strategies/{ticker}_strategies.pkl\", 'wb') as f:\n",
    "        pickle.dump(strategies, f)\n",
    "    \n",
    "    print(f\"✓ Strategies saved to data/llm_strategies/{ticker}_strategies.pkl\")\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "# Generate strategies\n",
    "strategies = precompute_llm_strategies(ticker, market_df, news_df, config)\n",
    "\n",
    "# Display sample strategies\n",
    "print(f\"\\nSample strategies:\")\n",
    "for i, strategy in enumerate(strategies[:3]):\n",
    "    print(f\"\\nStrategy {i+1}:\")\n",
    "    print(f\"  Direction: {strategy.direction}\")\n",
    "    print(f\"  Strength: {strategy.strength:.2f}\")\n",
    "    print(f\"  Signal (τ): {(2*strategy.direction-1) * strategy.strength:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "### 5.3 Train ReWTSE Ensemble\n",
    "\n",
    "This is the main training loop. It trains multiple DDQN agents on different time chunks and creates an ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train_ensemble"
   },
   "outputs": [],
   "source": [
    "def train_rewts_ensemble(ticker, market_df, strategies, config):\n",
    "    \"\"\"Train ReWTSE ensemble of DDQN agents\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training ReWTSE Ensemble for {ticker}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Initialize ensemble controller\n",
    "    ensemble = ReWTSEnsembleController(config['rewts'])\n",
    "    \n",
    "    # Determine number of chunks\n",
    "    chunk_length = config['rewts']['chunk_length']\n",
    "    num_chunks = len(market_df) // chunk_length\n",
    "    \n",
    "    print(f\"Total data points: {len(market_df)}\")\n",
    "    print(f\"Chunk length: {chunk_length}\")\n",
    "    print(f\"Number of chunks: {num_chunks}\")\n",
    "    print(f\"Episodes per chunk: {config['rewts']['episodes_per_chunk']}\")\n",
    "    \n",
    "    # Train a DDQN for each chunk\n",
    "    for chunk_id in range(num_chunks):\n",
    "        start_idx = chunk_id * chunk_length\n",
    "        end_idx = min((chunk_id + 1) * chunk_length, len(market_df))\n",
    "        \n",
    "        # Extract chunk data\n",
    "        chunk_df = market_df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # LLM strategies for this chunk\n",
    "        strategy_start_idx = start_idx // config['strategy_frequency']\n",
    "        strategy_end_idx = end_idx // config['strategy_frequency']\n",
    "        chunk_strategies = strategies[strategy_start_idx:strategy_end_idx]\n",
    "        \n",
    "        # Ensure we have strategies\n",
    "        if len(chunk_strategies) == 0:\n",
    "            print(f\"Warning: No strategies for chunk {chunk_id}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nChunk {chunk_id}: {len(chunk_df)} days, {len(chunk_strategies)} strategies\")\n",
    "        \n",
    "        # Create environment for the chunk\n",
    "        env = TradingEnv(chunk_df, chunk_strategies, config['trading_env'])\n",
    "        \n",
    "        # Train DDQN agent\n",
    "        agent = ensemble.train_chunk_model(\n",
    "            chunk_id=chunk_id,\n",
    "            env=env,\n",
    "            num_episodes=config['rewts']['episodes_per_chunk']\n",
    "        )\n",
    "        \n",
    "        ensemble.chunk_models.append(agent)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"✓ Ensemble training complete!\")\n",
    "    print(f\"  Total chunk models: {len(ensemble.chunk_models)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Train the ensemble\n",
    "ensemble = train_rewts_ensemble(ticker, market_df, strategies, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save"
   },
   "source": [
    "### 5.4 Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_model"
   },
   "outputs": [],
   "source": [
    "# Save the ensemble model\n",
    "os.makedirs('models', exist_ok=True)\n",
    "model_path = f\"models/{ticker}_rewts_ensemble.pkl\"\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(ensemble, f)\n",
    "\n",
    "print(f\"✓ Ensemble model saved to {model_path}\")\n",
    "\n",
    "# Save to Google Drive (only on Colab)\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        drive_models_path = '/content/drive/MyDrive/Papers/models'\n",
    "        os.makedirs(drive_models_path, exist_ok=True)\n",
    "        \n",
    "        drive_model_path = f\"{drive_models_path}/{ticker}_rewts_ensemble.pkl\"\n",
    "        with open(drive_model_path, 'wb') as f:\n",
    "            pickle.dump(ensemble, f)\n",
    "        \n",
    "        print(f\"✓ Ensemble model also saved to Google Drive: {drive_model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not save to Drive: {e}\")\n",
    "else:\n",
    "    print(f\"✓ Model saved locally in the project directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evaluation"
   },
   "source": [
    "## 6. Quick Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate"
   },
   "outputs": [],
   "source": [
    "# Quick evaluation on training data\n",
    "print(\"Evaluating ensemble on training data...\\n\")\n",
    "\n",
    "# Create evaluation environment\n",
    "eval_env = TradingEnv(market_df, strategies, config['trading_env'])\n",
    "\n",
    "# Initialize weights (uniform for now)\n",
    "if len(ensemble.chunk_models) > 0:\n",
    "    ensemble.current_weights = np.ones(len(ensemble.chunk_models)) / len(ensemble.chunk_models)\n",
    "\n",
    "state = eval_env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "actions_taken = []\n",
    "\n",
    "while not done:\n",
    "    # Get ensemble action\n",
    "    action, _ = ensemble.predict_ensemble(state)\n",
    "    actions_taken.append(action)\n",
    "    \n",
    "    # Execute action\n",
    "    state, reward, done, _ = eval_env.step(action)\n",
    "    total_reward += reward\n",
    "\n",
    "# Results\n",
    "final_portfolio_value = eval_env.portfolio_value\n",
    "initial_balance = config['trading_env']['initial_balance']\n",
    "total_return = (final_portfolio_value - initial_balance) / initial_balance * 100\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training Data Evaluation Results:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Initial Balance: ${initial_balance:,.2f}\")\n",
    "print(f\"Final Portfolio Value: ${final_portfolio_value:,.2f}\")\n",
    "print(f\"Total Return: {total_return:.2f}%\")\n",
    "print(f\"Total Reward: {total_reward:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Action distribution\n",
    "action_names = ['SHORT', 'HOLD', 'LONG']\n",
    "action_counts = np.bincount(actions_taken, minlength=3)\n",
    "print(f\"\\nAction Distribution:\")\n",
    "for i, name in enumerate(action_names):\n",
    "    pct = action_counts[i] / len(actions_taken) * 100\n",
    "    print(f\"  {name}: {action_counts[i]} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 7. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_results"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Plot portfolio value over time\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(eval_env.portfolio_history, label='Portfolio Value', linewidth=2)\n",
    "plt.axhline(y=initial_balance, color='r', linestyle='--', label='Initial Balance')\n",
    "plt.title(f'{ticker} - Portfolio Value Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Trading Steps')\n",
    "plt.ylabel('Portfolio Value ($)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "returns = np.diff(eval_env.portfolio_history) / eval_env.portfolio_history[:-1]\n",
    "plt.hist(returns, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.title('Return Distribution', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Performance metrics\n",
    "sharpe_ratio = np.mean(returns) / np.std(returns) * np.sqrt(252) if np.std(returns) > 0 else 0\n",
    "max_drawdown = np.min(returns) if len(returns) > 0 else 0\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Sharpe Ratio (annualized): {sharpe_ratio:.2f}\")\n",
    "print(f\"  Max Drawdown: {max_drawdown*100:.2f}%\")\n",
    "print(f\"  Volatility (annualized): {np.std(returns)*np.sqrt(252)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "After training, you can:\n",
    "\n",
    "1. **Backtest**: Run the backtesting script to evaluate on test data\n",
    "2. **Add more tickers**: Modify `config['tickers']` to train on multiple stocks\n",
    "3. **Tune hyperparameters**: Adjust learning rate, episodes, chunk length, etc.\n",
    "4. **Paper trading**: Use the Alpaca API to test on live data without real money\n",
    "5. **Analyze ensemble weights**: Examine how the QP optimization weights different chunks\n",
    "\n",
    "**Important Notes:**\n",
    "- Training may take several hours depending on data size and configuration\n",
    "- For production use, train on more episodes and larger datasets\n",
    "- Always validate on out-of-sample test data before real trading\n",
    "- Consider implementing proper train/validation/test splits\n",
    "- Monitor API usage and costs for Gemini calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_checkpoint"
   },
   "outputs": [],
   "source": [
    "# Save training checkpoint with metadata\n",
    "import datetime\n",
    "\n",
    "checkpoint = {\n",
    "    'ensemble': ensemble,\n",
    "    'strategies': strategies,\n",
    "    'config': config,\n",
    "    'ticker': ticker,\n",
    "    'training_date': datetime.datetime.now().isoformat(),\n",
    "    'data_period': {\n",
    "        'start': str(market_df.index.min()),\n",
    "        'end': str(market_df.index.max()),\n",
    "        'num_days': len(market_df)\n",
    "    },\n",
    "    'performance': {\n",
    "        'final_value': final_portfolio_value,\n",
    "        'total_return': total_return,\n",
    "        'sharpe_ratio': sharpe_ratio\n",
    "    }\n",
    "}\n",
    "\n",
    "checkpoint_path = f\"models/{ticker}_checkpoint_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "with open(checkpoint_path, 'wb') as f:\n",
    "    pickle.dump(checkpoint, f)\n",
    "\n",
    "print(f\"✓ Training checkpoint saved to {checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_rewts_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
