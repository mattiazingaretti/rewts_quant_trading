{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-colab"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mattiazingaretti/rewts_quant_trading/blob/master/notebooks/train_rewts_deepseek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReWTSE-LLM-RL Training Pipeline (DeepSeek)\n",
    "\n",
    "**Google Colab notebook using DeepSeek-V3.2 for LLM agents**\n",
    "\n",
    "This notebook provides a complete end-to-end pipeline:\n",
    "- \u2705 Data downloading and preprocessing\n",
    "- \u2705 LLM strategy generation with **DeepSeek** (caching and rate limiting)\n",
    "- \u2705 RL agent training (DDQN ensemble)\n",
    "- \u2705 Backtesting and evaluation\n",
    "- \u2705 Results visualization\n",
    "\n",
    "**System Architecture:**\n",
    "- **LLM Agent** (DeepSeek-V3.2): Strategic trading signals\n",
    "- **RL Agent** (DDQN): Tactical execution policies\n",
    "- **ReWTSE Ensemble**: Weighted ensemble with QP optimization\n",
    "\n",
    "**No Google Cloud Required!**\n",
    "- All training runs directly on Google Colab\n",
    "- DeepSeek API via OpenAI-compatible interface\n",
    "\n",
    "**Costs:**\n",
    "- Training 6 tickers: ~$0.21 (with 50% cache)\n",
    "- Annual (12x): ~$2.51/year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect environment (Colab or Local)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"\ud83d\ude80 Running on Google Colab\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print(\"\ud83d\udcbb Running locally\")\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (only on Colab)\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"\u2713 Google Drive mounted!\")\n",
    "else:\n",
    "    print(\"Skipping Google Drive mount (not on Colab)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup project path\n",
    "if IN_COLAB:\n",
    "    print(\"Google Colab Setup:\\n\")\n",
    "    print(\"Option 1: Clone from GitHub (Recommended)\")\n",
    "    !git clone https://github.com/mattiazingaretti/rewts_quant_trading.git\n",
    "    %cd rewts_quant_trading\n",
    "    \n",
    "    # Alternative: use from Google Drive\n",
    "    # Uncomment and modify the path to your project folder:\n",
    "    # project_path = '/content/drive/MyDrive/rewts_quant_trading'\n",
    "    # os.chdir(project_path)\n",
    "else:\n",
    "    print(\"Local Setup:\")\n",
    "    # Navigate to project root if needed\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('..')\n",
    "        print(\"Changed to project root directory\")\n",
    "\n",
    "print(f\"\\nCurrent working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "print(\"Installing dependencies...\\n\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q -r requirements.txt\n",
    "    print(\"\\n\u2713 Dependencies installed!\")\n",
    "else:\n",
    "    print(\"Local environment detected.\")\n",
    "    print(\"Make sure dependencies are installed: pip install -r requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Set your DeepSeek API key\n",
    "# Get your API key from: https://platform.deepseek.com\n",
    "\n",
    "DEEPSEEK_API_KEY = None\n",
    "\n",
    "# Method 1: Google Colab Secrets (recommended on Colab)\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
    "        print(\"\u2713 Using DEEPSEEK_API_KEY from Colab Secrets\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u2139\ufe0f  Colab Secrets not configured: {e}\")\n",
    "        print(\"   You can add secrets at: Runtime \u2192 Manage secrets \u2192 Add secret\")\n",
    "        print(\"   Name: DEEPSEEK_API_KEY, Value: sk-...\")\n",
    "\n",
    "# Method 2: Environment variables\n",
    "if DEEPSEEK_API_KEY is None and os.getenv('DEEPSEEK_API_KEY'):\n",
    "    DEEPSEEK_API_KEY = os.getenv('DEEPSEEK_API_KEY')\n",
    "    print(\"\u2713 Using DEEPSEEK_API_KEY from environment variables\")\n",
    "\n",
    "# Method 3: Manual input (fallback)\n",
    "if DEEPSEEK_API_KEY is None:\n",
    "    print(\"\\nEnter your DeepSeek API Key (input will be hidden)\")\n",
    "    DEEPSEEK_API_KEY = getpass('DeepSeek API Key: ')\n",
    "    print(\"\u2713 API key entered manually\")\n",
    "\n",
    "# Set environment variable\n",
    "os.environ['DEEPSEEK_API_KEY'] = DEEPSEEK_API_KEY\n",
    "\n",
    "print(\"\\n\u2713 API key configured!\")\n",
    "print(\"\\n\ud83d\udcb0 Estimated cost: ~$0.21 for 6 tickers (with cache)\")\n",
    "print(\"\\n\ud83d\udcda How to add Colab Secrets:\")\n",
    "print(\"  1. Click on \ud83d\udd11 icon in left sidebar (Secrets)\")\n",
    "print(\"  2. Click '+ Add new secret'\")\n",
    "print(\"  3. Name: DEEPSEEK_API_KEY\")\n",
    "print(\"  4. Value: sk-... (your API key)\")\n",
    "print(\"  5. Enable 'Notebook access'\")\n",
    "print(\"  6. Restart runtime and re-run cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Configuration\n",
    "config = {\n",
    "    # Tickers to train (you can add more)\n",
    "    'tickers': ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'META', 'TSLA'],\n",
    "    \n",
    "    # Data configuration\n",
    "    'start_date': '2012-01-01',\n",
    "    'end_date': '2020-12-31',\n",
    "    \n",
    "    # LLM Configuration (DeepSeek)\n",
    "    'llm': {\n",
    "        'llm_model': 'deepseek-chat',  # DeepSeek-V3.2\n",
    "        'temperature': 0.0,\n",
    "        'deepseek_api_key': os.getenv('DEEPSEEK_API_KEY'),\n",
    "    },\n",
    "    \n",
    "    # ReWTSE Configuration (Optimized)\n",
    "    'rewts': {\n",
    "        'chunk_length': 400,\n",
    "        'lookback_length': 200,\n",
    "        'forecast_horizon': 1,\n",
    "        'episodes_per_chunk': 100,\n",
    "        \n",
    "        # DDQN Hyperparameters\n",
    "        'gamma': 0.995,\n",
    "        'epsilon_start': 1.0,\n",
    "        'epsilon_min': 0.05,\n",
    "        'epsilon_decay': 0.998,\n",
    "        'learning_rate': 5e-4,\n",
    "        'batch_size': 128,\n",
    "        'buffer_size': 50000,\n",
    "        'target_update_freq': 20,\n",
    "        'hidden_dims': [256, 256, 128]\n",
    "    },\n",
    "    \n",
    "    # Trading Environment\n",
    "    'trading_env': {\n",
    "        'initial_balance': 10000,\n",
    "        'transaction_cost': 0.0015,\n",
    "        'max_position': 0.95,\n",
    "        'max_drawdown_limit': 0.15\n",
    "    },\n",
    "    \n",
    "    # Strategy generation frequency (days)\n",
    "    'strategy_frequency': 20,\n",
    "    \n",
    "    # Performance optimization\n",
    "    'parallel_workers': 8,  # Parallel LLM strategy generation\n",
    "    'max_requests_per_second': 8.0,  # Rate limiting for API\n",
    "    'skip_news_processing': False  # Skip news to save 50% API calls\n",
    "}\n",
    "\n",
    "import json\n",
    "print(\"Configuration (DeepSeek):\")\n",
    "print(\"=\"*70)\n",
    "print(json.dumps({k: v for k, v in config.items() if k != 'llm'}, indent=2))\n",
    "print(f\"\\nLLM Model: {config['llm']['llm_model']}\")\n",
    "print(f\"Tickers: {config['tickers']}\")\n",
    "print(f\"\\n\u26a0\ufe0f News processing: {'DISABLED' if config.get('skip_news_processing') else 'ENABLED'}\")\n",
    "if config.get('skip_news_processing'):\n",
    "    print(\"   (This saves 50% of API calls by using neutral sentiment)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add project to path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project modules (DeepSeek versions)\n",
    "from scripts.training.download_data import DataDownloader\n",
    "from src.llm_agents.strategist_agent_deepseek import StrategistAgent, TradingStrategy\n",
    "from src.llm_agents.analyst_agent_deepseek import AnalystAgent\n",
    "from src.rl_agents.trading_env import TradingEnv\n",
    "from src.hybrid_model.ensemble_controller import ReWTSEnsembleController\n",
    "from src.utils.data_utils import load_market_data, load_news_data, filter_news_by_period\n",
    "from src.utils.strategy_cache import StrategyCache\n",
    "from src.utils.rate_limiter import RateLimiter, RequestMonitor, retry_with_exponential_backoff\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "print(\"\u2713 Modules imported successfully!\")\n",
    "print(\"\u2713 Using DeepSeek agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Download\n",
    "\n",
    "Download and prepare market data for all tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data already exists\n",
    "data_missing = False\n",
    "for ticker in config['tickers']:\n",
    "    market_path = f\"data/processed/{ticker}_full_data.csv\"\n",
    "    news_path = f\"data/processed/{ticker}_news.csv\"\n",
    "    \n",
    "    if not os.path.exists(market_path) or not os.path.exists(news_path):\n",
    "        data_missing = True\n",
    "        break\n",
    "\n",
    "if data_missing:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Downloading market data...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    downloader = DataDownloader(config)\n",
    "    datasets = downloader.prepare_full_dataset()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u2713 Data download complete!\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"\u2713 All data already exists\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Verify data\n",
    "print(\"\\nData verification:\")\n",
    "for ticker in config['tickers']:\n",
    "    market_path = f\"data/processed/{ticker}_full_data.csv\"\n",
    "    if os.path.exists(market_path):\n",
    "        df = pd.read_csv(market_path, index_col=0)\n",
    "        print(f\"  {ticker}: \u2713 ({len(df)} days)\")\n",
    "    else:\n",
    "        print(f\"  {ticker}: \u2717 NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LLM Strategy Generation\n",
    "\n",
    "Generate trading strategies using Gemini LLM with:\n",
    "- **Smart caching**: Avoid duplicate API calls\n",
    "- **Rate limiting**: Respect API quotas\n",
    "- **Parallel execution**: Generate multiple strategies concurrently\n",
    "- **Automatic retry**: Handle rate limit errors gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_llm_strategies(ticker, market_df, news_df, config):\n",
    "    \"\"\"Generate LLM strategies with caching, rate limiting, and parallelization\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Generating LLM Strategies for {ticker}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Initialize cache and rate limiter\n",
    "    cache = StrategyCache()\n",
    "    max_workers = config.get('parallel_workers', 8)\n",
    "    max_rps = config.get('max_requests_per_second', 8.0)\n",
    "    skip_news = config.get('skip_news_processing', False)\n",
    "    \n",
    "    rate_limiter = RateLimiter(max_per_second=max_rps)\n",
    "    monitor = RequestMonitor(window_seconds=60, limit_rpm=1000)\n",
    "    \n",
    "    strategist = StrategistAgent(config['llm'])\n",
    "    analyst = AnalystAgent(config['llm']) if not skip_news else None\n",
    "    \n",
    "    print(f\"Parallel workers: {max_workers}\")\n",
    "    print(f\"Rate limit: {max_rps} req/s\")\n",
    "    if skip_news:\n",
    "        print(\"\u26a0\ufe0f  News processing DISABLED (saves 50% API calls)\")\n",
    "    \n",
    "    # Prepare tasks\n",
    "    strategy_frequency = config['strategy_frequency']\n",
    "    num_strategies = len(market_df) // strategy_frequency\n",
    "    \n",
    "    task_params = []\n",
    "    for i in range(num_strategies):\n",
    "        start_idx = i * strategy_frequency\n",
    "        end_idx = min((i + 1) * strategy_frequency, len(market_df))\n",
    "        period_data = market_df.iloc[start_idx:end_idx]\n",
    "        period_news = filter_news_by_period(news_df, period_data.index[0], period_data.index[-1])\n",
    "        \n",
    "        # Prepare input data\n",
    "        market_data = {\n",
    "            'timestamp': str(period_data.index[-1]),\n",
    "            'Close': float(period_data['Close'].iloc[-1]),\n",
    "            'Volume': float(period_data['Volume'].iloc[-1]),\n",
    "            'Weekly_Returns': period_data['Close'].pct_change().tail(20).tolist(),\n",
    "            'HV_Close': float(period_data.get('HV_Close', pd.Series([0])).iloc[-1]),\n",
    "            'Beta': 1.0,\n",
    "            'Classification': 'Growth'\n",
    "        }\n",
    "        \n",
    "        fundamentals = {\n",
    "            'current_ratio': float(period_data.get('Current_Ratio', pd.Series([1.5])).iloc[-1]),\n",
    "            'debt_to_equity': float(period_data.get('Debt_to_Equity', pd.Series([0.5])).iloc[-1]),\n",
    "            'pe_ratio': float(period_data.get('PE_Ratio', pd.Series([20])).iloc[-1]),\n",
    "            'gross_margin': float(period_data.get('Gross_Margin', pd.Series([0.4])).iloc[-1]),\n",
    "            'operating_margin': float(period_data.get('Operating_Margin', pd.Series([0.2])).iloc[-1]),\n",
    "            'eps_yoy': 0.1,\n",
    "            'net_income_yoy': 0.1\n",
    "        }\n",
    "        \n",
    "        analytics = {\n",
    "            'ma_20': float(period_data['SMA_20'].iloc[-1]),\n",
    "            'ma_50': float(period_data['SMA_50'].iloc[-1]),\n",
    "            'ma_200': float(period_data['SMA_200'].iloc[-1]),\n",
    "            'ma_20_slope': float(period_data['SMA_20_Slope'].iloc[-1]),\n",
    "            'ma_50_slope': float(period_data['SMA_50_Slope'].iloc[-1]),\n",
    "            'rsi': float(period_data['RSI'].iloc[-1]),\n",
    "            'macd': float(period_data['MACD'].iloc[-1]),\n",
    "            'macd_signal': float(period_data['MACD_Signal'].iloc[-1]),\n",
    "            'atr': float(period_data['ATR'].iloc[-1])\n",
    "        }\n",
    "        \n",
    "        macro_data = {\n",
    "            'SPX_Close': float(period_data.get('SPX_Close', pd.Series([0])).iloc[-1]),\n",
    "            'VIX_Close': float(period_data.get('VIX_Close', pd.Series([0])).iloc[-1]),\n",
    "            'GDP_QoQ': 0.0,\n",
    "            'PMI': 50.0\n",
    "        }\n",
    "        \n",
    "        task_params.append({\n",
    "            'task_id': i,\n",
    "            'period_news': period_news,\n",
    "            'market_data': market_data,\n",
    "            'fundamentals': fundamentals,\n",
    "            'analytics': analytics,\n",
    "            'macro_data': macro_data\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nPrepared {len(task_params)} strategy generation tasks\")\n",
    "    \n",
    "    # Worker function\n",
    "    def generate_single_strategy(params):\n",
    "        task_id = params['task_id']\n",
    "        \n",
    "        # Process news\n",
    "        if skip_news or len(params['period_news']) == 0 or analyst is None:\n",
    "            news_signals = {'sentiment': 'neutral', 'confidence': 0.5, 'key_topics': []}\n",
    "        else:\n",
    "            news_signals = analyst.process_news(params['period_news'].to_dict('records'))\n",
    "        \n",
    "        # Check cache\n",
    "        cached = cache.get(\n",
    "            ticker=ticker,\n",
    "            market_data=params['market_data'],\n",
    "            fundamentals=params['fundamentals'],\n",
    "            analytics=params['analytics'],\n",
    "            macro_data=params['macro_data'],\n",
    "            news_signals=news_signals,\n",
    "            model_name=config['llm']['llm_model'],\n",
    "            temperature=config['llm']['temperature']\n",
    "        )\n",
    "        \n",
    "        if cached is not None:\n",
    "            return {'task_id': task_id, 'strategy': TradingStrategy(**cached), 'from_cache': True}\n",
    "        \n",
    "        # Generate with rate limiting\n",
    "        rate_limiter.wait()\n",
    "        monitor.record_request()\n",
    "        \n",
    "        try:\n",
    "            strategy = retry_with_exponential_backoff(\n",
    "                lambda: strategist.generate_strategy(\n",
    "                    market_data=params['market_data'],\n",
    "                    fundamentals=params['fundamentals'],\n",
    "                    analytics=params['analytics'],\n",
    "                    macro_data=params['macro_data'],\n",
    "                    news_signals=news_signals,\n",
    "                    last_strategy=None\n",
    "                ),\n",
    "                max_retries=3,\n",
    "                initial_wait=2.0,\n",
    "                max_wait=30.0\n",
    "            )\n",
    "            \n",
    "            # Save to cache\n",
    "            cache.set(\n",
    "                ticker=ticker,\n",
    "                market_data=params['market_data'],\n",
    "                fundamentals=params['fundamentals'],\n",
    "                analytics=params['analytics'],\n",
    "                macro_data=params['macro_data'],\n",
    "                news_signals=news_signals,\n",
    "                model_name=config['llm']['llm_model'],\n",
    "                temperature=config['llm']['temperature'],\n",
    "                strategy=strategy\n",
    "            )\n",
    "            \n",
    "            return {'task_id': task_id, 'strategy': strategy, 'from_cache': False}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n\u274c Failed strategy {task_id}: {e}\")\n",
    "            # Fallback\n",
    "            return {\n",
    "                'task_id': task_id,\n",
    "                'strategy': TradingStrategy(\n",
    "                    direction=1, confidence=1.5, strength=0.5,\n",
    "                    explanation=f'Fallback: {str(e)}',\n",
    "                    features_used=[], timestamp=params['market_data']['timestamp']\n",
    "                ),\n",
    "                'from_cache': False, 'error': True\n",
    "            }\n",
    "    \n",
    "    # Execute in parallel\n",
    "    print(f\"\\n\ud83d\ude80 Starting parallel generation...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    strategies_dict = {}\n",
    "    cache_hits = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(generate_single_strategy, p): p['task_id'] for p in task_params}\n",
    "        \n",
    "        for i, future in enumerate(as_completed(futures), 1):\n",
    "            result = future.result()\n",
    "            strategies_dict[result['task_id']] = result['strategy']\n",
    "            if result['from_cache']:\n",
    "                cache_hits += 1\n",
    "            \n",
    "            if i % 10 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                rate = i / elapsed\n",
    "                eta = (len(task_params) - i) / rate if rate > 0 else 0\n",
    "                print(f\"Progress: {i}/{len(task_params)} ({100*i/len(task_params):.1f}%) | \"\n",
    "                      f\"Rate: {rate:.1f} strat/s | ETA: {eta:.0f}s\")\n",
    "    \n",
    "    # Reorder strategies\n",
    "    strategies = [strategies_dict[i] for i in range(len(task_params))]\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n\u2713 Generated {len(strategies)} strategies in {elapsed:.1f}s\")\n",
    "    print(f\"  Cache hits: {cache_hits} ({100*cache_hits/len(strategies):.1f}%)\")\n",
    "    print(f\"  API calls saved: {cache_hits}\")\n",
    "    \n",
    "    # Save strategies\n",
    "    os.makedirs('data/llm_strategies', exist_ok=True)\n",
    "    with open(f\"data/llm_strategies/{ticker}_strategies.pkl\", 'wb') as f:\n",
    "        pickle.dump(strategies, f)\n",
    "    \n",
    "    return strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. RL Ensemble Training\n",
    "\n",
    "Train DDQN agents on different time chunks and create a weighted ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rewts_ensemble(ticker, market_df, strategies, config):\n",
    "    \"\"\"Train ReWTSE ensemble of DDQN agents\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training ReWTSE Ensemble for {ticker}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    ensemble = ReWTSEnsembleController(config['rewts'])\n",
    "    \n",
    "    chunk_length = config['rewts']['chunk_length']\n",
    "    num_chunks = len(market_df) // chunk_length\n",
    "    \n",
    "    print(f\"Data points: {len(market_df)}\")\n",
    "    print(f\"Chunk length: {chunk_length}\")\n",
    "    print(f\"Number of chunks: {num_chunks}\")\n",
    "    print(f\"Episodes per chunk: {config['rewts']['episodes_per_chunk']}\")\n",
    "    \n",
    "    for chunk_id in range(num_chunks):\n",
    "        start_idx = chunk_id * chunk_length\n",
    "        end_idx = min((chunk_id + 1) * chunk_length, len(market_df))\n",
    "        \n",
    "        chunk_df = market_df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        strategy_start = start_idx // config['strategy_frequency']\n",
    "        strategy_end = end_idx // config['strategy_frequency']\n",
    "        chunk_strategies = strategies[strategy_start:strategy_end]\n",
    "        \n",
    "        if len(chunk_strategies) == 0:\n",
    "            print(f\"\u26a0\ufe0f No strategies for chunk {chunk_id}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nChunk {chunk_id}: {len(chunk_df)} days, {len(chunk_strategies)} strategies\")\n",
    "        \n",
    "        env = TradingEnv(chunk_df, chunk_strategies, config['trading_env'])\n",
    "        agent = ensemble.train_chunk_model(\n",
    "            chunk_id=chunk_id,\n",
    "            env=env,\n",
    "            num_episodes=config['rewts']['episodes_per_chunk']\n",
    "        )\n",
    "        \n",
    "        ensemble.chunk_models.append(agent)\n",
    "    \n",
    "    print(f\"\\n\u2713 Ensemble training complete! ({len(ensemble.chunk_models)} models)\")\n",
    "    return ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Complete Training Pipeline\n",
    "\n",
    "Execute the full training pipeline for all tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track training results\ntrained_models = {}\n\nprint(\"=\"*80)\nprint(\"MULTI-TICKER TRAINING PIPELINE\")\nprint(\"=\"*80)\nprint(f\"Tickers: {config['tickers']}\")\nprint(f\"Estimated time: ~20-30 min per ticker\")\nprint(\"=\"*80)\n\n# Import garbage collector for memory cleanup\nimport gc\n\nfor idx, ticker in enumerate(config['tickers'], 1):\n    print(f\"\\n{'#'*80}\")\n    print(f\"# [{idx}/{len(config['tickers'])}] Processing {ticker}\")\n    print(f\"{'#'*80}\")\n    \n    # Check if model exists\n    model_path = f\"models/{ticker}_rewts_ensemble.pkl\"\n    if os.path.exists(model_path):\n        print(f\"\u2713 Model already exists: {model_path}\")\n        # Don't load into memory, just note it exists\n        print(f\"  Skipping training for {ticker}\")\n        print(f\"  (Model not loaded to save RAM)\")\n        continue\n    \n    try:\n        # 1. Load data\n        print(f\"\\n[1/4] Loading data...\")\n        market_df = load_market_data(ticker)\n        news_df = load_news_data(ticker)\n        print(f\"  \u2713 Market: {len(market_df)} days | News: {len(news_df)} articles\")\n        \n        # 2. Generate strategies\n        print(f\"\\n[2/4] Generating LLM strategies...\")\n        strategies = precompute_llm_strategies(ticker, market_df, news_df, config)\n        print(f\"  \u2713 Generated {len(strategies)} strategies\")\n        \n        # Free memory after strategy generation\n        del market_df, news_df\n        gc.collect()\n        \n        # Reload market data for training\n        market_df = load_market_data(ticker)\n        \n        # 3. Train ensemble\n        print(f\"\\n[3/4] Training ReWTSE ensemble...\")\n        ensemble = train_rewts_ensemble(ticker, market_df, strategies, config)\n        print(f\"  \u2713 Trained {len(ensemble.chunk_models)} chunk models\")\n        \n        # Free memory after training\n        del market_df, strategies\n        gc.collect()\n        \n        # 4. Save model\n        print(f\"\\n[4/4] Saving model...\")\n        os.makedirs('models', exist_ok=True)\n        with open(model_path, 'wb') as f:\n            pickle.dump(ensemble, f)\n        print(f\"  \u2713 Saved to {model_path}\")\n        \n        # Save to Google Drive if on Colab\n        if IN_COLAB:\n            try:\n                drive_path = '/content/drive/MyDrive/rewts_models'\n                os.makedirs(drive_path, exist_ok=True)\n                drive_model_path = f\"{drive_path}/{ticker}_rewts_ensemble.pkl\"\n                with open(drive_model_path, 'wb') as f:\n                    pickle.dump(ensemble, f)\n                print(f\"  \u2713 Also saved to Google Drive\")\n            except Exception as e:\n                print(f\"  \u26a0\ufe0f Could not save to Drive: {e}\")\n        \n        # Don't keep in memory - free it!\n        print(f\"\\n\ud83d\udcbe Freeing memory...\")\n        del ensemble\n        gc.collect()\n        \n        print(f\"\\n{'='*80}\")\n        print(f\"\u2705 {ticker} training complete!\")\n        print(f\"{'='*80}\")\n        \n        # Print memory usage if psutil available\n        try:\n            import psutil\n            process = psutil.Process()\n            mem_info = process.memory_info()\n            mem_mb = mem_info.rss / 1024 / 1024\n            print(f\"\ud83d\udcca Current memory usage: {mem_mb:.1f} MB\")\n        except ImportError:\n            pass\n        \n    except Exception as e:\n        print(f\"\\n{'='*80}\")\n        print(f\"\u274c Error training {ticker}: {e}\")\n        print(f\"{'='*80}\")\n        import traceback\n        traceback.print_exc()\n        \n        # Clean up on error\n        gc.collect()\n        continue\n\nprint(f\"\\n{'='*80}\")\nprint(f\"TRAINING COMPLETE\")\nprint(f\"{'='*80}\")\nprint(f\"Models saved in: models/\")\nif IN_COLAB:\n    print(f\"Also saved to: /content/drive/MyDrive/rewts_models/\")\nprint(f\"{'='*80}\")\nprint(f\"\\n\ud83d\udca1 Note: Models not kept in memory to save RAM\")\nprint(f\"   Load them individually for backtesting if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Backtesting\n",
    "\n",
    "Evaluate trained models on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(portfolio_history, initial_balance=10000):\n    \"\"\"Calculate trading metrics\"\"\"\n    if len(portfolio_history) == 0:\n        return {'total_return': 0.0, 'sharpe_ratio': 0.0, 'max_drawdown': 0.0, \n                'volatility': 0.0, 'win_rate': 0.0}\n    \n    portfolio_values = np.array(portfolio_history)\n    final_value = portfolio_values[-1]\n    total_return = (final_value - initial_balance) / initial_balance\n    \n    returns = np.diff(portfolio_values) / portfolio_values[:-1]\n    returns = returns[np.isfinite(returns)]\n    \n    if len(returns) == 0 or np.std(returns) == 0:\n        return {'total_return': total_return, 'sharpe_ratio': 0.0, \n                'max_drawdown': 0.0, 'volatility': 0.0, 'win_rate': 0.0}\n    \n    sharpe_ratio = (np.mean(returns) / np.std(returns)) * np.sqrt(252)\n    peak = np.maximum.accumulate(portfolio_values)\n    drawdowns = (peak - portfolio_values) / peak\n    max_drawdown = np.max(drawdowns)\n    volatility = np.std(returns) * np.sqrt(252)\n    win_rate = (returns > 0).sum() / len(returns)\n    \n    return {\n        'total_return': total_return,\n        'sharpe_ratio': sharpe_ratio,\n        'max_drawdown': max_drawdown,\n        'volatility': volatility,\n        'win_rate': win_rate\n    }\n\nprint(\"=\"*80)\nprint(\"BACKTESTING\")\nprint(\"=\"*80)\nprint(\"\\n\ud83d\udca1 Loading models one at a time to save RAM\\n\")\n\nresults = []\n\n# Import garbage collector\nimport gc\n\nfor ticker in config['tickers']:\n    model_path = f\"models/{ticker}_rewts_ensemble.pkl\"\n    \n    if not os.path.exists(model_path):\n        print(f\"\\n\u26a0\ufe0f Model not found for {ticker}\")\n        continue\n    \n    print(f\"\\n{'='*60}\")\n    print(f\"Evaluating {ticker}\")\n    print(f\"{'='*60}\")\n    \n    try:\n        # Load model\n        print(f\"Loading model...\")\n        with open(model_path, 'rb') as f:\n            ensemble = pickle.load(f)\n        \n        # Load strategies\n        with open(f\"data/llm_strategies/{ticker}_strategies.pkl\", 'rb') as f:\n            strategies = pickle.load(f)\n        \n        # Load market data\n        market_df = load_market_data(ticker)\n        \n        # Create environment\n        eval_env = TradingEnv(market_df, strategies, config['trading_env'])\n        ensemble.current_weights = np.ones(len(ensemble.chunk_models)) / len(ensemble.chunk_models)\n        \n        # Run evaluation\n        state = eval_env.reset()\n        done = False\n        actions_taken = []\n        \n        while not done:\n            action, _ = ensemble.predict_ensemble(state)\n            actions_taken.append(action)\n            state, reward, done, _ = eval_env.step(action)\n        \n        # Calculate metrics\n        initial_balance = config['trading_env']['initial_balance']\n        final_value = eval_env.portfolio_value\n        metrics = calculate_metrics(eval_env.portfolio_history, initial_balance)\n        \n        # Print results\n        print(f\"Initial Balance:  ${initial_balance:,.2f}\")\n        print(f\"Final Value:      ${final_value:,.2f}\")\n        print(f\"Total Return:     {metrics['total_return']:.2%}\")\n        print(f\"Sharpe Ratio:     {metrics['sharpe_ratio']:.2f}\")\n        print(f\"Max Drawdown:     {metrics['max_drawdown']:.2%}\")\n        print(f\"Volatility:       {metrics['volatility']:.2%}\")\n        print(f\"Win Rate:         {metrics['win_rate']:.2%}\")\n        \n        results.append({\n            'ticker': ticker,\n            'final_value': final_value,\n            'metrics': metrics\n        })\n        \n        # Free memory after each ticker\n        print(f\"\\nFreeing memory...\")\n        del ensemble, strategies, market_df, eval_env, actions_taken\n        gc.collect()\n        \n    except Exception as e:\n        print(f\"\u2717 Error: {e}\")\n        gc.collect()\n\n# Summary\nif len(results) > 0:\n    print(f\"\\n{'='*80}\")\n    print(\"SUMMARY\")\n    print(f\"{'='*80}\")\n    \n    print(f\"\\n{'Ticker':<10} {'Return':<12} {'Sharpe':<10} {'Max DD':<12} {'Volatility':<12}\")\n    print(\"-\"*60)\n    \n    for r in results:\n        m = r['metrics']\n        print(f\"{r['ticker']:<10} {m['total_return']:<12.2%} {m['sharpe_ratio']:<10.2f} \"\n              f\"{m['max_drawdown']:<12.2%} {m['volatility']:<12.2%}\")\n    \n    # Averages\n    avg_return = np.mean([r['metrics']['total_return'] for r in results])\n    avg_sharpe = np.mean([r['metrics']['sharpe_ratio'] for r in results])\n    avg_dd = np.mean([r['metrics']['max_drawdown'] for r in results])\n    avg_vol = np.mean([r['metrics']['volatility'] for r in results])\n    \n    print(\"-\"*60)\n    print(f\"{'AVERAGE':<10} {avg_return:<12.2%} {avg_sharpe:<10.2f} {avg_dd:<12.2%} {avg_vol:<12.2%}\")\n    print(\"=\"*80)\nelse:\n    print(\"\\n\u2717 No results to display\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if len(results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Total returns\n",
    "    tickers = [r['ticker'] for r in results]\n",
    "    returns = [r['metrics']['total_return'] * 100 for r in results]\n",
    "    \n",
    "    axes[0].bar(tickers, returns, color='steelblue', edgecolor='black')\n",
    "    axes[0].set_title('Total Return (%)', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Return (%)')\n",
    "    axes[0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Sharpe ratios\n",
    "    sharpes = [r['metrics']['sharpe_ratio'] for r in results]\n",
    "    \n",
    "    axes[1].bar(tickers, sharpes, color='green', edgecolor='black')\n",
    "    axes[1].set_title('Sharpe Ratio', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('Sharpe Ratio')\n",
    "    axes[1].axhline(y=1.0, color='red', linestyle='--', label='Target: 1.0')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\u2713 Visualization complete!\")\n",
    "else:\n",
    "    print(\"No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Next Steps\n",
    "\n",
    "After training, you can:\n",
    "\n",
    "1. **Download models**: Models are saved locally and to Google Drive (if on Colab)\n",
    "2. **Paper trading**: Use the trained models with Alpaca API for paper trading\n",
    "3. **Hyperparameter tuning**: Adjust learning rate, episodes, chunk length, etc.\n",
    "4. **Add more tickers**: Extend the ticker list in configuration\n",
    "5. **Analyze ensemble weights**: Examine QP optimization results\n",
    "\n",
    "**Important Notes:**\n",
    "- Training time: ~20-30 minutes per ticker\n",
    "- API usage: ~50-100 Gemini API calls per ticker (with caching and news skipping)\n",
    "- Always validate on out-of-sample data before real trading\n",
    "- Consider proper train/validation/test splits for production use\n",
    "\n",
    "---\n",
    "\n",
    "\ud83e\udd16 **Complete training pipeline for Google Colab**  \n",
    "\u2728 **No Google Cloud deployment required**  \n",
    "\u26a1 **Optimized with caching, rate limiting, and parallelization**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}